{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "geographic-watershed",
   "metadata": {},
   "source": [
    "\n",
    "# CSE 40 Take-Home Final: ajbhatia\n",
    "\n",
    "Your unique dataset consists of physiochemical properties of a selection of Portuguese Vinho Verde wines.\n",
    "\n",
    "Some wines are red, some are white. A boolean label for high-quality white wines has been provided.\n",
    "\n",
    "You are free to use any library code provided within the `cse40` conda environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "after-democrat",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "%matplotlib widget\n",
    "\n",
    "# Import stats to be used for outlier detection\n",
    "from scipy import stats \n",
    "\n",
    "df = pd.read_csv('data.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c5ee11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# DATA CLEANING AND MANIPULATION\n",
    "\n",
    "# exact the first number from a string and return just the number as a float\n",
    "def extract_first_number(source_str):\n",
    "    '''\n",
    "    extract the first numerical value appearing in a string\n",
    "    as a float and return it, allowing negative numbers and \n",
    "    decimal values\n",
    "    '''\n",
    "    \n",
    "    # `source_str` does not contain interpretable data\n",
    "    if pd.isna(source_str) or source_str.startswith('NA'):\n",
    "        \n",
    "        # use `np.nan` to represent missing data\n",
    "        return np.nan\n",
    "\n",
    "    # find instances of a valid numerical substrings in the source string\n",
    "    # see https://regex101.com/r/gwP6Qy/2 for an explanation\n",
    "    matches = re.search(r'-?\\d+\\.?\\d*', source_str.replace(',', ''))\n",
    "    \n",
    "    # if there are any valid numerical substrings\n",
    "    if matches:\n",
    "        return float(matches[0])                                  # convert the first one to a float and return the value\n",
    "    else:\n",
    "        return np.nan                                             # otherwise, treat as missing data\n",
    "    \n",
    "# change True/False values into 1s and 0s\n",
    "def one_hot(source_bool):\n",
    "    if source_bool == True:\n",
    "        return 1                                                  # if value is true, replace it with 1\n",
    "    else:\n",
    "        return 0                                                  # if value is false, replace it with 0\n",
    "    \n",
    "# call extract_first_number on specific columns\n",
    "def replace_str(df, exclude_columns=[]):\n",
    "    \n",
    "    for c in df.columns:                                          # loop through columns that are included and extract first numbers\n",
    "        if c not in exclude_columns:          \n",
    "            df[c] = (df[c].apply(extract_first_number))\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    return df                                                     # return the extracted df\n",
    "\n",
    "# count the number of true values and false values and print them\n",
    "def true_false(df):\n",
    "    true = 0\n",
    "    false = 0\n",
    "    for i in df['quality white']:\n",
    "        if i == True:\n",
    "            true += 1                                            # if a true value appears, increment true variable\n",
    "        else:\n",
    "            false += 1                                           # if a false value appears, increment false variable\n",
    "    print(\"The number of trues in quality white:\", true)\n",
    "    print(\"The number of falses in quality white:\", false)\n",
    "    \n",
    "df = df.dropna()                                                  # drop all rows with NaN values\n",
    "\n",
    "df = replace_str(df, ['quality white','pH'])                      # filter out strings and data information\n",
    "\n",
    "df['quality white'] = (df['quality white'].apply(one_hot))        # perform one hot encoding for quality white column\n",
    "\n",
    "df = df[(np.abs(stats.zscore(df)) < 3).all(axis=1)]               # detect and remove outliers from data set\n",
    "\n",
    "true_false(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ed130a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# VISUALIZATION WITH CORRELATION PLOTS\n",
    "\n",
    "# adds new feature value plot at a specific spot in the vertical stack\n",
    "def plot_bestfit(column, n): \n",
    "    x = (df[column]).to_numpy()\n",
    "    y = (df[\"quality white\"]).to_numpy()\n",
    "    m, b = np.polyfit(x, y, 1)\n",
    "    axs[n].plot(x, m*x + b)\n",
    "    axs[n].set_title(column)\n",
    "\n",
    "# plot correlation matrix for feature values with \"quality white\"\n",
    "f = plt.figure(figsize=(12, 6))\n",
    "plt.matshow(df.corr(), fignum=f.number)\n",
    "plt.xticks(range(df.select_dtypes(['number']).shape[1]), df.select_dtypes(['number']).columns, fontsize=14, rotation=45)\n",
    "plt.yticks(range(df.select_dtypes(['number']).shape[1]), df.select_dtypes(['number']).columns, fontsize=14)\n",
    "cb = plt.colorbar()\n",
    "cb.ax.tick_params(labelsize=14)\n",
    "plt.title('Correlation Matrix', fontsize=16);\n",
    "    \n",
    "# plot vertically stacked correlation plots\n",
    "fig, axs = plt.subplots(5)\n",
    "fig.suptitle(\"Feature Value Correlation Plots\")\n",
    "fig.set_size_inches(10, 10)\n",
    "\n",
    "plot_bestfit(\"volatile acidity\", 0)\n",
    "plot_bestfit(\"alcohol\", 1)\n",
    "plot_bestfit(\"citric acid\", 2)\n",
    "plot_bestfit(\"free sulfur dioxide\", 3)\n",
    "plot_bestfit(\"pH\", 4)\n",
    "\n",
    "plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=0.9, \n",
    "                    top=0.9, \n",
    "                    wspace=0, \n",
    "                    hspace=1.5)\n",
    "\n",
    "plt.show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31d9b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns that are least correlated with column \"quality white\"\n",
    "df = df.drop(columns=[\"volatile acidity\", \"citric acid\", \"pH\"])\n",
    "\n",
    "# transform df into a Scaler\n",
    "scaler = StandardScaler()\n",
    "scaled_array = scaler.fit_transform(df)\n",
    "df = pd.DataFrame(scaled_array, columns=df.columns, index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf92f670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN, PLOT, AND VALIDATE MODELS\n",
    "\n",
    "# find k-fold validate scores\n",
    "def K_Fold_Validate(models, kf, X, y):\n",
    "    \n",
    "    # initialize dictionary to hold scores\n",
    "    scores = {\n",
    "        name: [] for name in models\n",
    "    }\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "    \n",
    "        # split training test sets by index\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        # compute the cross-validation score for each model\n",
    "        # using the same splits\n",
    "        for name, model in models.items():\n",
    "\n",
    "            model.fit(X_train, y_train.to_numpy().ravel())\n",
    "        \n",
    "            scores[name].append(\n",
    "                f1_score(y_test, model.predict(X_test), zero_division=0)\n",
    "            )\n",
    "\n",
    "    return {k: np.array(v) for k, v in scores.items()}\n",
    "\n",
    "# train models with model.fit function\n",
    "def train(model, df):\n",
    "    model.fit(df[[\"alcohol\", \"free sulfur dioxide\"]], (df[\"quality white\"] > 0).values.ravel())\n",
    "    return None\n",
    "\n",
    "# find K Fold Validate scores\n",
    "linear_model = SGDClassifier(\n",
    "    loss='log',\n",
    "    random_state=0\n",
    ")\n",
    "tree_model = DecisionTreeClassifier(\n",
    "    criterion='entropy',\n",
    "    max_depth=5,\n",
    "    random_state=0\n",
    ")\n",
    "knn_model = KNeighborsClassifier(\n",
    "    n_neighbors=8\n",
    ")\n",
    "\n",
    "# define models\n",
    "models = {\n",
    "    'linear': linear_model,\n",
    "    'tree': tree_model, \n",
    "    'KNN': knn_model\n",
    "}\n",
    "\n",
    "# suppress errors\n",
    "tree_model.fit(np.array([[1,1]]), np.array([[1]]))\n",
    "knn_model.fit(np.array([[1,1]]*10), np.array([[1]]*10))\n",
    "\n",
    "# call your function\n",
    "train(tree_model, df)\n",
    "train(knn_model, df)\n",
    "\n",
    "# plot decision boundaries\n",
    "features = ['alcohol', 'free sulfur dioxide']\n",
    "label = ['quality white']\n",
    "\n",
    "# data range\n",
    "x_min, x_max = df[features[0]].min() - 1, df[features[0]].max() + 1\n",
    "y_min, y_max = df[features[1]].min() - 1, df[features[1]].max() + 1\n",
    "\n",
    "# meshgrid\n",
    "res = (x_max - x_min) / 100\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, res), np.arange(y_min, y_max, res))\n",
    "\n",
    "Z_tree = tree_model.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "Z_knn = knn_model.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, sharey=True, figsize=(10, 4))\n",
    "ax1.scatter(df[features[0]], df[features[1]], c=np.array(df[label] > 0), alpha=0.5)\n",
    "ax1.contourf(xx, yy, Z_tree, alpha=0.2)\n",
    "ax1.set_xlabel(f'Relative {features[0]}'), \n",
    "ax1.set_ylabel(f'Relative {features[1]}'), ax1.set_title('Decision Tree')\n",
    "\n",
    "ax2.scatter(df[features[0]], df[features[1]], c=np.array(df[label] > 0), alpha=0.5)\n",
    "ax2.contourf(xx, yy, Z_knn, alpha=0.2)\n",
    "ax2.set_xlabel(f'Relative {features[0]}'), ax2.set_title('K Nearest Neighbors')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# define X and y values\n",
    "X, y = df[features], df[label] < 0\n",
    "\n",
    "k = 5\n",
    "kf = KFold(k)\n",
    "\n",
    "scores = K_Fold_Validate(models, kf, X, y)\n",
    "\n",
    "# print out k-fold validation scores for each model\n",
    "print('K Fold Validation:')\n",
    "for k, v in scores.items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12bd52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIND AND PLOT P-VALUES FOR THE DIFFERENT MODELS USED\n",
    "\n",
    "# return probability of null hypothesis \n",
    "def t_stat(model1_scores, model2_scores):\n",
    "    deltaI = np.subtract(model1_scores, model2_scores)\n",
    "    deltaBar = np.mean(deltaI)\n",
    "    sDelta = np.sqrt(np.mean((deltaI-deltaBar)*(deltaI-deltaBar)))\n",
    "    denominater = (sDelta)/(np.sqrt(len(model1_scores)-1))\n",
    "    t = (deltaBar)/denominater\n",
    "    \n",
    "    # compute the pvalue from a two-tailed t-statistic `t`\n",
    "    pval = stats.t.sf(np.abs(t), len(model1_scores)-1) * 2\n",
    "    \n",
    "    return pval\n",
    "\n",
    "# reset KFold and k to calculate the f1 value\n",
    "k = int(np.sqrt(len(X)))\n",
    "kf = KFold(k)\n",
    "\n",
    "# recall scores\n",
    "scores = K_Fold_Validate(models, kf, X, y)\n",
    "\n",
    "# prints out the p_val for each pair of models\n",
    "def report(a, b):\n",
    "    pval = t_stat(scores[a], scores[b])\n",
    "    print(f'prob. that avg. f1 score for {a} and {b} are the same:', pval)\n",
    "\n",
    "# call report with each pair of model\n",
    "report('linear', 'tree')\n",
    "report('linear', 'KNN')\n",
    "report('KNN', 'tree')\n",
    "    \n",
    "# plot f1 values\n",
    "fig = plt.figure()\n",
    "fig.suptitle('f1 Score Comparison using K-Fold Cross-Validation')\n",
    "ax = fig.add_subplot(111)\n",
    "for i, (k, v) in enumerate(scores.items()):\n",
    "    ax.scatter(i * np.ones(len(v)) + 1, v, label=k, alpha=0.5)\n",
    "for i in range(len(scores['linear'])):\n",
    "    ax.plot([1, 2, 3], [scores[k][i] for k in scores.keys()], c='k', alpha=0.2)\n",
    "ax.boxplot(scores.values())\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4c3e8c",
   "metadata": {},
   "source": [
    "## <span style=\"color: blue;\">Analysis</span>\n",
    "\n",
    "\n",
    "The main relationships that I noticed were the correlations between quality white and alcohol and free sulfur dioxide. This was shown explicitly through the models I used and their results on the test data. In order to maximize the impact of these relationships, I dropped all other feature variables so that the only columns that were taken into account by the model were alcohol and free sulfur dioxide and how they apply to the label, quality white. I believed that removing these other features helped better my model accuracy.\n",
    "\n",
    "I applied many different concepts from this class to this project in order to complete it. Mainly, I used the eight steps to clean data, importing data, merging sets, rebuilding missing data, standardization, normalization, deduplication, verification, and exporting the data. I focused on a few of these eight steps to ensure that my data was cleaned properly. Mainly, removing data, standardization, and normalization. Additionally, when training my models, the concept of overfitting was clear to me so that I could ensure my model would not be incredibly complex. This motivated me to find the middle ground between a complex model that would overfit my training data and a model that would be complex enough to accurately represent my data with high accuracy. Lastly, the talk of using P-values in order to determine if our models were statistically significant is something that I was able to apply to this project. Since P-values depict whether or not we should reject or accept a null hypothesis, I used this metric to see if my models were performing the way they were depending on random chance. I ended up finding that the opposite was true, and the models were statistically significant because of how they compared to my other models. None of my p-values were below 0.05, so there was not enough evidence to reject any null hypotheses.\n",
    "\n",
    "Changing the max_depth variable resulted in a very interesting error with how the model displayed the data. When choosing a higher max_depth, the model would sometimes display nothing. I think this occurred because when we have a high max_depth size, our model becomes increasingly complex. This can cause overfitting of our model and make it so that the test accuracy of the model is incredibly low. To avoid this concept of overfitting and ensure that model runs correctly, I chose a smaller max_depth size so that the model was much simpler and properly represented the data.\n",
    "\n",
    "Similar to the max_depth variable, the n_neighbors counter needed to be limited in order to ensure that my model was not incredibly complex, and thus avoiding overfitting. But, when changing the value, I found that sometimes a lower value resulted in a less complicated model and, in turn, resulted in lower mean accuracy. To balance this, I found a middle ground between a complicated model and a simple model, as to have the largest possible mean accuracy, while still avoiding overfitting.\n",
    "\n",
    "If I had more time to work on this data set, I would try to create an algorithm based on something other than a categorical label. I have rarely seen models without categorical labels, so I think it would be interesting to try to find something without much variation, like the pH, depending on the citric acid and alcohol. Additionally, I would like to explore how to use more than two feature values to help classify the label. By using three or more feature values I would be able to compare the F1 scores of the models to the ones I used for this project and see if it would be better or worse. Also, with three or more values, I would be able to see how it affects the complexity of the models and if it makes it more likely for my models to overfit the training data. There many different things that I would be able to do with this data set if I had more time, but the relationships that I found between my feature values and label value were incredible to see, especially because of how well my models worked on identifying the proper classification."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
